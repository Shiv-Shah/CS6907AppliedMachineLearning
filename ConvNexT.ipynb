{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_U8TpHBwozs",
        "outputId": "3c30d560-6a3f-4469-a6e9-d9e34a36f45b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet_pytorch) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet_pytorch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=02ece6678b7fd19d715e29cd654b1f5f00fff21d571372fc9f9404ef8d5b09c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: efficientnet_pytorch\n",
            "Successfully installed efficientnet_pytorch-0.7.1\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXNin-pGz79t",
        "outputId": "31b9e71d-ac18-47b3-8fb1-9d77e55040e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',  force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLYKYrVnwbkW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets, models\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "input_folder_path_train = \"/content/drive/MyDrive/images/preprocessed/train\"\n",
        "output_folder_path_train = \"/content/drive/MyDrive/images/preprocessed/train_cropped\"\n",
        "input_folder_path_test = \"/content/drive/MyDrive/images/preprocessed/test\"\n",
        "output_folder_path_test = \"/content/drive/MyDrive/images/preprocessed/test_cropped\"\n",
        "new_width = 255  # Set the desired width\n",
        "new_height = 255  # Set the desired height\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fY_iol34wc1J"
      },
      "outputs": [],
      "source": [
        "def resize_and_break(input_folder, output_folder, new_width, new_height):\n",
        "    # Create output folder and subfolders(classes) if they doesn't exist\n",
        "    outputs = ['class_1','class_2','class_3','class_4','class_5','class_6','class_7','class_8']\n",
        "    if not os.path.exists(output_folder):\n",
        "            os.makedirs(output_folder)\n",
        "    for i in outputs:\n",
        "        folder_path = os.path.join(output_folder, i)\n",
        "        if not os.path.exists(folder_path):\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "    # Loop through all files in the input folder\n",
        "    if input_folder == '/content/drive/MyDrive/images/preprocessed/train':\n",
        "        csv_train = os.path.join(input_folder, \"CSAW-M_train.csv\")\n",
        "        df_label = pd.read_csv(csv_train,sep = ';')\n",
        "    else:\n",
        "        csv_test = os.path.join(input_folder, \"CSAW-M_test.csv\")\n",
        "        df_label = pd.read_csv(csv_test,sep = ';')\n",
        "\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(('.png', '.jpg', '.jpeg', '.gif')):  # Add more extensions if needed\n",
        "            # Grab label for file\n",
        "            label = df_label.loc[df_label['Filename'] == filename, 'Label'].values[0]\n",
        "\n",
        "            # Assign output folder based on label\n",
        "            folder_path = os.path.join(os.path.join(output_folder, 'class_'+str(label)))\n",
        "\n",
        "            # Construct full file paths\n",
        "            input_path = os.path.join(input_folder, filename)\n",
        "\n",
        "            # Open the image\n",
        "            image = Image.open(input_path)\n",
        "\n",
        "            # Resize the image\n",
        "            resized_image = image.resize((new_width, new_height), Image.LANCZOS)\n",
        "\n",
        "            # Get the file name (without extension) from the input path\n",
        "            file_name = os.path.splitext(filename)[0]\n",
        "\n",
        "            # Save the resized image to the correct label folder\n",
        "            output_path = os.path.join(folder_path, f\"{file_name}_resized.jpg\")\n",
        "            resized_image.save(output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GT_l8HBUwkW2"
      },
      "outputs": [],
      "source": [
        "# Uncomment to resize and label data\n",
        "resize_and_break(input_folder_path_train, output_folder_path_train, new_width, new_height)\n",
        "resize_and_break(input_folder_path_test, output_folder_path_test, new_width, new_height)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSvQwd17wgOw",
        "outputId": "42fa2b2d-31ac-45be-cb5d-99288500e955"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Cuda supported: True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b4_rwightman-7eb33cd5.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b4_rwightman-7eb33cd5.pth\n",
            "100%|██████████| 74.5M/74.5M [00:00<00:00, 432MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5, Loss: 1.9678809550784577\n",
            "Validation Accuracy: 25.15%\n",
            "Epoch 2/5, Loss: 1.7571620633138105\n",
            "Validation Accuracy: 38.43%\n",
            "Epoch 3/5, Loss: 1.6561600445900988\n",
            "Validation Accuracy: 36.02%\n",
            "Epoch 4/5, Loss: 1.5101421883442259\n",
            "Validation Accuracy: 36.42%\n",
            "Epoch 5/5, Loss: 1.2680543105074222\n",
            "Validation Accuracy: 29.58%\n"
          ]
        }
      ],
      "source": [
        "# Define your dataset and dataloaders\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((380, 380)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Replace 'your_dataset_directory' with the path to your dataset\n",
        "train_dataset = datasets.ImageFolder(root=output_folder_path_train, transform=data_transform)\n",
        "val_dataset = datasets.ImageFolder(root=output_folder_path_test, transform=data_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "\n",
        "#from torchvision.models import efficientnet_b4, EfficientNet_b4_Weights\n",
        "from torchvision.models._api import WeightsEnum\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "def get_state_dict(self, *args, **kwargs):\n",
        "    kwargs.pop(\"check_hash\")\n",
        "    return load_state_dict_from_url(self.url, *args, **kwargs)\n",
        "WeightsEnum.get_state_dict = get_state_dict\n",
        "\n",
        "#efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "#efficientnet_b0(weights=\"DEFAULT\")\n",
        "\n",
        "# Instantiate the model\n",
        "print(f\"Is Cuda supported: {torch.cuda.is_available()}\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.convnext_tiny(weights=models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1)\n",
        "model = models.convnext_tiny(weights=\"DEFAULT\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 5  # You can increase this number for better training\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'efficientnetb4_model.pth')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
