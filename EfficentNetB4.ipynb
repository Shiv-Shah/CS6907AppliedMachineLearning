{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install efficientnet_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_U8TpHBwozs",
        "outputId": "0697313c-1662-47f6-8c32-88773098a39e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.10/dist-packages (0.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet_pytorch) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet_pytorch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',  force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXNin-pGz79t",
        "outputId": "458727e3-bd00-4453-ffa7-85bd81edcfff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets, models\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "input_folder_path_train = \"/content/drive/MyDrive/images/preprocessed/train\"\n",
        "output_folder_path_train = \"/content/drive/MyDrive/images/preprocessed/train_cropped\"\n",
        "input_folder_path_test = \"/content/drive/MyDrive/images/preprocessed/test\"\n",
        "output_folder_path_test = \"/content/drive/MyDrive/images/preprocessed/test_cropped\"\n",
        "new_width = 255  # Set the desired width\n",
        "new_height = 255  # Set the desired height\n"
      ],
      "metadata": {
        "id": "bLYKYrVnwbkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_and_break(input_folder, output_folder, new_width, new_height):\n",
        "    # Create output folder and subfolders(classes) if they doesn't exist\n",
        "    outputs = ['class_1','class_2','class_3','class_4','class_5','class_6','class_7','class_8']\n",
        "    if not os.path.exists(output_folder):\n",
        "            os.makedirs(output_folder)\n",
        "    for i in outputs:\n",
        "        folder_path = os.path.join(output_folder, i)\n",
        "        if not os.path.exists(folder_path):\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "    # Loop through all files in the input folder\n",
        "    if input_folder == '/content/drive/MyDrive/images/preprocessed/train':\n",
        "        csv_train = os.path.join(input_folder, \"CSAW-M_train.csv\")\n",
        "        df_label = pd.read_csv(csv_train,sep = ';')\n",
        "    else:\n",
        "        csv_test = os.path.join(input_folder, \"CSAW-M_test.csv\")\n",
        "        df_label = pd.read_csv(csv_test,sep = ';')\n",
        "\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(('.png', '.jpg', '.jpeg', '.gif')):  # Add more extensions if needed\n",
        "            # Grab label for file\n",
        "            label = df_label.loc[df_label['Filename'] == filename, 'Label'].values[0]\n",
        "\n",
        "            # Assign output folder based on label\n",
        "            folder_path = os.path.join(os.path.join(output_folder, 'class_'+str(label)))\n",
        "\n",
        "            # Construct full file paths\n",
        "            input_path = os.path.join(input_folder, filename)\n",
        "\n",
        "            # Open the image\n",
        "            image = Image.open(input_path)\n",
        "\n",
        "            # Resize the image\n",
        "            resized_image = image.resize((new_width, new_height), Image.LANCZOS)\n",
        "\n",
        "            # Get the file name (without extension) from the input path\n",
        "            file_name = os.path.splitext(filename)[0]\n",
        "\n",
        "            # Save the resized image to the correct label folder\n",
        "            output_path = os.path.join(folder_path, f\"{file_name}_resized.jpg\")\n",
        "            resized_image.save(output_path)"
      ],
      "metadata": {
        "id": "fY_iol34wc1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment to resize and label data\n",
        "resize_and_break(input_folder_path_train, output_folder_path_train, new_width, new_height)\n",
        "resize_and_break(input_folder_path_test, output_folder_path_test, new_width, new_height)\n"
      ],
      "metadata": {
        "id": "GT_l8HBUwkW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your dataset and dataloaders\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((380, 380)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Replace 'your_dataset_directory' with the path to your dataset\n",
        "train_dataset = datasets.ImageFolder(root=output_folder_path_train, transform=data_transform)\n",
        "val_dataset = datasets.ImageFolder(root=output_folder_path_test, transform=data_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "# Instantiate the model\n",
        "model = models.efficientnet_b4(False)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 5  # You can increase this number for better training\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'efficientnetb4_model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSvQwd17wgOw",
        "outputId": "947b08fd-fde4-4a36-fcd3-7af7d724782f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    }
  ]
}