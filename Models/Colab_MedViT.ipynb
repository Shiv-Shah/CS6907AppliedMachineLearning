{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD9uOPEK65K0",
        "outputId": "1253ddfb-dc4b-4767-8c4c-db6f8a5a6f7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec 13 00:56:25 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   74C    P0    43W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "metadata": {
        "id": "Cuy5nHfrQH6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Omid-Nejati/MedViT.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AwVn7yc7Soj",
        "outputId": "a5e44e6d-5e66-4410-c5a5-2f802d6d02f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MedViT' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/MedViT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y051lFG77tXO",
        "outputId": "60d6e3d0-7c32-4ed2-b64f-dab1c4c0e823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MedViT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision.utils\n",
        "from torchvision import models\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n"
      ],
      "metadata": {
        "id": "lgm5vmQp8i9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model"
      ],
      "metadata": {
        "id": "1ta2wQYk78Mg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmPD4BBg7708",
        "outputId": "9ddfa0bb-2980-4cc8-d457-397730ae3469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (0.9.12)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from MedViT import MedViT_small as tiny"
      ],
      "metadata": {
        "id": "GEQ5S3_U8E0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tiny()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKcyvB0Y8RsK",
        "outputId": "e7281e1d-5131-4ee9-adfc-b975d00f4243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.proj_head[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35YD-2Ul8aaV",
        "outputId": "ea9e7900-25cd-40f9-e1ab-4a25e8f58984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=1024, out_features=1000, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.proj_head[0] = torch.nn.Linear(in_features=1024, out_features=8, bias=True)"
      ],
      "metadata": {
        "id": "0RE8qlwf8ZV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.cuda()"
      ],
      "metadata": {
        "id": "dFXm96Gi8g7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset"
      ],
      "metadata": {
        "id": "nIefIFDW80-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install medmnist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yVawz1S84b3",
        "outputId": "f2e16623-630a-4574-ad8e-fc1512b2e03e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: medmnist in /usr/local/lib/python3.10/dist-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.19.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.66.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (9.4.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.5.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.16.0+cu118)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2023.3.post1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.2.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2023.9.26)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (23.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->medmnist) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->medmnist) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',  force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JY-aelYJhQB",
        "outputId": "42556eb9-85a0-4647-84bf-c65389c0c18c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator"
      ],
      "metadata": {
        "id": "ChBhSTxK87hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_flag = 'breastmnist'\n",
        "# [tissuemnist, pathmnist, chestmnist, dermamnist, octmnist,\n",
        "# pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]\n",
        "download = True\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 10\n",
        "lr = 0.005\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])"
      ],
      "metadata": {
        "id": "rH1INOxS8-iM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms.transforms import Resize\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets, models\n",
        "import torch.utils.data as data_utils\n",
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import scipy.stats as stats\n",
        "import statistics\n",
        "import numpy as np\n",
        "input_folder_path_train = \"/content/drive/MyDrive/images/preprocessed/train\"\n",
        "output_folder_path_train = \"/content/drive/MyDrive/images/preprocessed/train_cropped\"\n",
        "input_folder_path_test = \"/content/drive/MyDrive/images/preprocessed/test\"\n",
        "output_folder_path_test = \"/content/drive/MyDrive/images/preprocessed/test_cropped\"\n",
        "new_width = 255  # Set the desired width\n",
        "new_height = 255  # Set the desired height\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=output_folder_path_train, transform=data_transform)\n",
        "val_dataset = datasets.ImageFolder(root=output_folder_path_test, transform=data_transform)\n",
        "\n",
        "indices_train = torch.arange(4000)\n",
        "indices_test = torch.arange(400)\n",
        "\n",
        "train_dataset_sample = data_utils.Subset(train_dataset,indices_train)\n",
        "test_dataset_sample = data_utils.Subset(val_dataset,indices_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset_sample, batch_size=32, shuffle=True, num_workers=8)\n",
        "val_loader = DataLoader(test_dataset_sample, batch_size=32, shuffle=True, num_workers=8)\n",
        "\n",
        "\n",
        "# load the data\n",
        "# Replace 'your_dataset_directory' with the path to your dataset\n",
        "train_dataset = datasets.ImageFolder(root=output_folder_path_train, transform=data_transform)\n",
        "val_dataset = datasets.ImageFolder(root=output_folder_path_test, transform=data_transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD22o8uW9L1X",
        "outputId": "f62dadc0-9a1b-4cbc-98f6-5ddbac5ff894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset)\n",
        "print(\"===================\")\n",
        "print(val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNjqCTnI9T9w",
        "outputId": "5b8d0aad-0d9e-4269-a968-f3031a26e461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ImageFolder\n",
            "    Number of datapoints: 9523\n",
            "    Root location: /content/drive/MyDrive/images/preprocessed/train_cropped\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n",
            "               ToTensor()\n",
            "           )\n",
            "===================\n",
            "Dataset ImageFolder\n",
            "    Number of datapoints: 497\n",
            "    Root location: /content/drive/MyDrive/images/preprocessed/test_cropped\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n",
            "               ToTensor()\n",
            "           )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "g-ImKp2m9cLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define loss function and optimizer\n",
        "if task == \"multi-label, binary-class\":\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "else:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
      ],
      "metadata": {
        "id": "gMy_aJrE9eeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jFdOE-C7QGNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    print('Epoch [%d/%d]'% (epoch+1, NUM_EPOCHS))\n",
        "    model.train()\n",
        "    for inputs, targets in tqdm(train_loader):\n",
        "        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        # forward + backward + optimize\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        if task == 'multi-label, binary-class':\n",
        "            targets = targets.to(torch.float32)\n",
        "            loss = criterion(outputs, targets)\n",
        "        else:\n",
        "            targets = targets.squeeze().long()\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmIo3JWf9lEs",
        "outputId": "7739c138-686c-45e4-d371-e2e01f922277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [02:23<00:00,  1.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [02:14<00:00,  1.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [02:16<00:00,  1.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [02:15<00:00,  1.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [02:15<00:00,  1.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [02:15<00:00,  1.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [02:14<00:00,  1.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [02:14<00:00,  1.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [02:16<00:00,  1.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [02:14<00:00,  1.08s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test"
      ],
      "metadata": {
        "id": "XRkfM6CM91j8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "import scipy.stats as stats\n",
        "import statistics\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "# evaluation\n",
        "# Local variables for logging results\n",
        "best_per_epoch = [[],[]]\n",
        "best_MAE = 99999    # Set defualt to an artifically high number\n",
        "best_tau = 0\n",
        "def test(split):\n",
        "    model.eval()\n",
        "    y_true = torch.tensor([]).cuda()\n",
        "    y_score = torch.tensor([]).cuda()\n",
        "\n",
        "    data_loader = val_dataset\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    epoch_lowest_MAE = 99999    # Set defualt to an artifically high number\n",
        "    epoch_log = [[],[]]\n",
        "    with torch.no_grad():\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        for inputs, targets  in tqdm(val_loader):\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            if task == 'multi-label, binary-class':\n",
        "                targets = targets.to(torch.float32)\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "            else:\n",
        "                targets = targets.squeeze().long()\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "                targets = targets.float().resize_(len(targets), 1)\n",
        "\n",
        "\n",
        "            y_true = torch.cat((y_true, targets), 0)\n",
        "            y_score = torch.cat((y_score, outputs), 0)\n",
        "\n",
        "            inputs, targets = inputs.to('cpu'), targets.to('cpu')\n",
        "            outputs = outputs.to('cpu')\n",
        "\n",
        "            [all_preds.append(torch.argmax(i).item()) for i in outputs]\n",
        "            [all_labels.append(i.item()) for i in targets]\n",
        "\n",
        "            total += outputs.size(0)\n",
        "            correct += (outputs == targets).sum().item()\n",
        "\n",
        "        y_true = y_true.cpu().numpy()\n",
        "        y_score = y_score.detach().cpu().numpy()\n",
        "\n",
        "        #evaluator = Evaluator(data_flag, split)\n",
        "        #metrics = evaluator.evaluate(y_score)\n",
        "\n",
        "        #print('%s  auc: %.3f  acc:%.3f' % (split, *metrics))\n",
        "        print(all_preds, all_labels)\n",
        "        #all_preds = all_preds.numpy()\n",
        "        #all_labels = all_labels.numpy()\n",
        "        tau, p_value = stats.kendalltau(all_preds, all_labels)\n",
        "        epoch_Tau = tau\n",
        "\n",
        "        # Calc mae\n",
        "        label_set = list(set(all_labels))\n",
        "        all_mae = []\n",
        "        for label in label_set:\n",
        "            index_list = [i for i, x in enumerate(all_labels) if x == label]\n",
        "            pred_list = [all_preds[i] for i in index_list]\n",
        "            label_list = [all_labels[i] for i in index_list]\n",
        "            mae = mean_absolute_error(pred_list, label_list)\n",
        "            all_mae.append(mae)\n",
        "        epoch_MAE = np.average(all_mae)\n",
        "\n",
        "        accuracy = correct / total\n",
        "        print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "        epoch_log[0].append(epoch_MAE)\n",
        "        epoch_log[1].append(epoch_Tau)\n",
        "\n",
        "\n",
        "    MAE_average = statistics.mean(epoch_log[0])\n",
        "    Tau_average = statistics.mean(epoch_log[1])\n",
        "\n",
        "    MAE_deviation = statistics.pstdev(epoch_log[0])\n",
        "    Tau_deviation = statistics.pstdev(epoch_log[1])\n",
        "\n",
        "\n",
        "    print(f\"AMAE value: {MAE_average} +- {MAE_deviation}\")\n",
        "    print(f\"TAU value: {Tau_average} +- {Tau_deviation}\")\n",
        "\n",
        "\n",
        "print('==> Evaluating ...')\n",
        "test('test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCSBTpUy93r-",
        "outputId": "bd1a558d-e280-43c7-8e91-10f71a238dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Evaluating ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:06<00:00,  1.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 1, 0, 0, 3, 3, 3, 3, 3, 0, 3, 3, 3, 1, 3, 3, 2, 3, 1, 1, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 2, 3, 2, 1, 0, 1, 3, 3, 3, 1, 3, 1, 3, 1, 3, 3, 3, 3, 0, 3, 3, 2, 0, 3, 1, 3, 1, 1, 0, 1, 1, 3, 1, 3, 3, 3, 2, 1, 1, 2, 1, 2, 1, 1, 1, 3, 3, 3, 3, 3, 1, 3, 3, 3, 2, 3, 3, 3, 1, 3, 1, 3, 1, 0, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 1, 0, 1, 0, 1, 3, 1, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 1, 1, 0, 3, 3, 3, 3, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 1, 3, 1, 1, 1, 3, 0, 3, 0, 3, 3, 3, 1, 3, 1, 1, 1, 3, 1, 3, 1, 3, 1, 1, 3, 3, 3, 3, 3, 3, 1, 3, 0, 3, 1, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 1, 3, 3, 2, 2, 3, 1, 1, 3, 3, 1, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 0, 3, 1, 3, 1, 3, 1, 3, 2, 1, 3, 1, 1, 2, 3, 3, 1, 0, 3, 3, 1, 3, 1, 0, 3, 2, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 1, 1, 3, 3, 1, 3, 3, 3, 3, 3, 1, 2, 3, 3, 1, 3, 3, 3, 1, 3, 2, 3, 1, 3, 0, 3, 3, 2, 1, 3, 3, 1, 3, 0, 1, 3, 3, 3, 3, 3, 3, 3, 2, 3, 1, 2, 3, 3, 1, 3, 3, 3, 3, 3, 1, 3, 1, 3, 1, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3, 2, 2, 3, 3, 3, 3, 2, 1, 3, 1, 3, 1, 1, 1, 3, 3, 1, 0, 3, 1, 3, 1, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 2, 1, 3, 0, 3] [4.0, 3.0, 0.0, 1.0, 4.0, 4.0, 3.0, 5.0, 4.0, 1.0, 4.0, 5.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 1.0, 2.0, 4.0, 4.0, 4.0, 3.0, 1.0, 3.0, 3.0, 2.0, 1.0, 1.0, 5.0, 3.0, 3.0, 2.0, 4.0, 2.0, 3.0, 1.0, 3.0, 3.0, 4.0, 3.0, 1.0, 3.0, 3.0, 1.0, 0.0, 4.0, 2.0, 4.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 4.0, 5.0, 2.0, 3.0, 1.0, 1.0, 3.0, 2.0, 3.0, 3.0, 3.0, 1.0, 4.0, 5.0, 4.0, 4.0, 5.0, 3.0, 3.0, 4.0, 3.0, 4.0, 4.0, 3.0, 2.0, 1.0, 3.0, 1.0, 4.0, 1.0, 1.0, 3.0, 4.0, 5.0, 0.0, 5.0, 4.0, 3.0, 2.0, 3.0, 3.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 4.0, 3.0, 1.0, 3.0, 4.0, 4.0, 3.0, 4.0, 2.0, 4.0, 1.0, 1.0, 2.0, 4.0, 3.0, 5.0, 3.0, 2.0, 3.0, 3.0, 5.0, 5.0, 3.0, 4.0, 1.0, 4.0, 4.0, 1.0, 4.0, 3.0, 3.0, 3.0, 4.0, 0.0, 1.0, 1.0, 2.0, 4.0, 5.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 5.0, 2.0, 4.0, 5.0, 4.0, 1.0, 2.0, 4.0, 4.0, 4.0, 5.0, 4.0, 4.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 3.0, 3.0, 3.0, 1.0, 4.0, 3.0, 4.0, 2.0, 4.0, 1.0, 2.0, 4.0, 3.0, 3.0, 3.0, 5.0, 1.0, 4.0, 2.0, 2.0, 2.0, 4.0, 1.0, 1.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 5.0, 2.0, 4.0, 3.0, 3.0, 4.0, 1.0, 5.0, 4.0, 4.0, 3.0, 5.0, 2.0, 5.0, 3.0, 5.0, 0.0, 4.0, 1.0, 3.0, 1.0, 4.0, 1.0, 4.0, 2.0, 2.0, 5.0, 2.0, 1.0, 3.0, 4.0, 2.0, 2.0, 1.0, 4.0, 4.0, 1.0, 5.0, 1.0, 1.0, 4.0, 2.0, 5.0, 5.0, 3.0, 1.0, 0.0, 3.0, 3.0, 4.0, 5.0, 3.0, 2.0, 3.0, 3.0, 5.0, 3.0, 2.0, 3.0, 2.0, 2.0, 3.0, 4.0, 2.0, 3.0, 5.0, 4.0, 2.0, 2.0, 3.0, 2.0, 3.0, 4.0, 0.0, 1.0, 4.0, 4.0, 3.0, 1.0, 3.0, 4.0, 4.0, 3.0, 3.0, 3.0, 2.0, 3.0, 0.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0, 4.0, 3.0, 5.0, 4.0, 2.0, 3.0, 5.0, 2.0, 4.0, 5.0, 3.0, 4.0, 4.0, 1.0, 3.0, 1.0, 3.0, 2.0, 2.0, 3.0, 3.0, 5.0, 3.0, 3.0, 4.0, 0.0, 2.0, 5.0, 3.0, 4.0, 3.0, 4.0, 2.0, 4.0, 3.0, 4.0, 4.0, 3.0, 3.0, 4.0, 0.0, 4.0, 3.0, 1.0, 1.0, 5.0, 4.0, 1.0, 1.0, 3.0, 1.0, 3.0, 0.0, 3.0, 4.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 4.0, 3.0, 3.0, 4.0, 1.0, 3.0, 3.0, 5.0, 2.0, 1.0, 4.0, 1.0, 4.0]\n",
            "Validation Accuracy: 0.00%\n",
            "AMAE value: 0.9092883967883968 +- 0.0\n",
            "TAU value: 0.6118131594620827 +- 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}